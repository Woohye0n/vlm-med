{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.999878335631438,
  "eval_steps": 500,
  "global_step": 24657,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012166436856192717,
      "grad_norm": 14.75,
      "learning_rate": 9.959443565721702e-05,
      "loss": 8.2186,
      "step": 100
    },
    {
      "epoch": 0.024332873712385433,
      "grad_norm": 8.5625,
      "learning_rate": 9.918887131443404e-05,
      "loss": 5.2424,
      "step": 200
    },
    {
      "epoch": 0.03649931056857815,
      "grad_norm": 7.59375,
      "learning_rate": 9.878330697165105e-05,
      "loss": 3.6742,
      "step": 300
    },
    {
      "epoch": 0.04866574742477087,
      "grad_norm": 10.9375,
      "learning_rate": 9.837774262886808e-05,
      "loss": 4.2619,
      "step": 400
    },
    {
      "epoch": 0.06083218428096358,
      "grad_norm": 10.125,
      "learning_rate": 9.797217828608509e-05,
      "loss": 3.2744,
      "step": 500
    },
    {
      "epoch": 0.0729986211371563,
      "grad_norm": 8.25,
      "learning_rate": 9.756661394330212e-05,
      "loss": 4.4694,
      "step": 600
    },
    {
      "epoch": 0.08516505799334902,
      "grad_norm": 34.75,
      "learning_rate": 9.716104960051913e-05,
      "loss": 3.1441,
      "step": 700
    },
    {
      "epoch": 0.09733149484954173,
      "grad_norm": 20.625,
      "learning_rate": 9.675548525773614e-05,
      "loss": 3.294,
      "step": 800
    },
    {
      "epoch": 0.10949793170573445,
      "grad_norm": 26.875,
      "learning_rate": 9.634992091495316e-05,
      "loss": 2.8915,
      "step": 900
    },
    {
      "epoch": 0.12166436856192717,
      "grad_norm": 13.3125,
      "learning_rate": 9.594435657217018e-05,
      "loss": 3.0746,
      "step": 1000
    },
    {
      "epoch": 0.13383080541811987,
      "grad_norm": 39.5,
      "learning_rate": 9.55387922293872e-05,
      "loss": 2.734,
      "step": 1100
    },
    {
      "epoch": 0.1459972422743126,
      "grad_norm": 12.75,
      "learning_rate": 9.513322788660421e-05,
      "loss": 2.8793,
      "step": 1200
    },
    {
      "epoch": 0.1581636791305053,
      "grad_norm": 14.375,
      "learning_rate": 9.472766354382124e-05,
      "loss": 3.5611,
      "step": 1300
    },
    {
      "epoch": 0.17033011598669803,
      "grad_norm": 69.0,
      "learning_rate": 9.432209920103825e-05,
      "loss": 3.3891,
      "step": 1400
    },
    {
      "epoch": 0.18249655284289074,
      "grad_norm": 11.9375,
      "learning_rate": 9.391653485825527e-05,
      "loss": 3.1579,
      "step": 1500
    },
    {
      "epoch": 0.19466298969908347,
      "grad_norm": 7.71875,
      "learning_rate": 9.351097051547229e-05,
      "loss": 2.9969,
      "step": 1600
    },
    {
      "epoch": 0.20682942655527617,
      "grad_norm": 8.8125,
      "learning_rate": 9.31054061726893e-05,
      "loss": 3.0508,
      "step": 1700
    },
    {
      "epoch": 0.2189958634114689,
      "grad_norm": 16.125,
      "learning_rate": 9.269984182990632e-05,
      "loss": 3.0158,
      "step": 1800
    },
    {
      "epoch": 0.2311623002676616,
      "grad_norm": 67.5,
      "learning_rate": 9.229427748712333e-05,
      "loss": 2.8221,
      "step": 1900
    },
    {
      "epoch": 0.24332873712385433,
      "grad_norm": 7.34375,
      "learning_rate": 9.188871314434036e-05,
      "loss": 3.8438,
      "step": 2000
    },
    {
      "epoch": 0.25549517398004706,
      "grad_norm": 5.34375,
      "learning_rate": 9.148314880155737e-05,
      "loss": 3.0204,
      "step": 2100
    },
    {
      "epoch": 0.26766161083623974,
      "grad_norm": 4.15625,
      "learning_rate": 9.10775844587744e-05,
      "loss": 2.8295,
      "step": 2200
    },
    {
      "epoch": 0.27982804769243247,
      "grad_norm": 47.5,
      "learning_rate": 9.067202011599141e-05,
      "loss": 3.2413,
      "step": 2300
    },
    {
      "epoch": 0.2919944845486252,
      "grad_norm": 5.0625,
      "learning_rate": 9.026645577320842e-05,
      "loss": 3.8421,
      "step": 2400
    },
    {
      "epoch": 0.30416092140481793,
      "grad_norm": 26.0,
      "learning_rate": 8.986089143042544e-05,
      "loss": 3.2678,
      "step": 2500
    },
    {
      "epoch": 0.3163273582610106,
      "grad_norm": 4.375,
      "learning_rate": 8.945532708764246e-05,
      "loss": 2.9806,
      "step": 2600
    },
    {
      "epoch": 0.32849379511720334,
      "grad_norm": 8.125,
      "learning_rate": 8.904976274485948e-05,
      "loss": 3.1601,
      "step": 2700
    },
    {
      "epoch": 0.34066023197339607,
      "grad_norm": 6.03125,
      "learning_rate": 8.864419840207649e-05,
      "loss": 2.9776,
      "step": 2800
    },
    {
      "epoch": 0.3528266688295888,
      "grad_norm": 8.1875,
      "learning_rate": 8.823863405929352e-05,
      "loss": 3.19,
      "step": 2900
    },
    {
      "epoch": 0.36499310568578147,
      "grad_norm": 13.875,
      "learning_rate": 8.783306971651053e-05,
      "loss": 2.6952,
      "step": 3000
    },
    {
      "epoch": 0.3771595425419742,
      "grad_norm": 8.0,
      "learning_rate": 8.742750537372754e-05,
      "loss": 3.0089,
      "step": 3100
    },
    {
      "epoch": 0.38932597939816693,
      "grad_norm": 1.1796875,
      "learning_rate": 8.702194103094457e-05,
      "loss": 3.116,
      "step": 3200
    },
    {
      "epoch": 0.40149241625435966,
      "grad_norm": 8.375,
      "learning_rate": 8.661637668816158e-05,
      "loss": 2.8117,
      "step": 3300
    },
    {
      "epoch": 0.41365885311055234,
      "grad_norm": 29.5,
      "learning_rate": 8.62108123453786e-05,
      "loss": 3.1956,
      "step": 3400
    },
    {
      "epoch": 0.42582528996674507,
      "grad_norm": 5.3125,
      "learning_rate": 8.580524800259561e-05,
      "loss": 3.6631,
      "step": 3500
    },
    {
      "epoch": 0.4379917268229378,
      "grad_norm": 4.25,
      "learning_rate": 8.539968365981264e-05,
      "loss": 2.839,
      "step": 3600
    },
    {
      "epoch": 0.45015816367913053,
      "grad_norm": 3.046875,
      "learning_rate": 8.499411931702965e-05,
      "loss": 3.2829,
      "step": 3700
    },
    {
      "epoch": 0.4623246005353232,
      "grad_norm": 24.0,
      "learning_rate": 8.458855497424666e-05,
      "loss": 2.8639,
      "step": 3800
    },
    {
      "epoch": 0.47449103739151594,
      "grad_norm": 15.6875,
      "learning_rate": 8.418299063146369e-05,
      "loss": 3.0076,
      "step": 3900
    },
    {
      "epoch": 0.48665747424770867,
      "grad_norm": 37.0,
      "learning_rate": 8.37774262886807e-05,
      "loss": 3.2746,
      "step": 4000
    },
    {
      "epoch": 0.4988239111039014,
      "grad_norm": 9.25,
      "learning_rate": 8.337186194589773e-05,
      "loss": 3.0062,
      "step": 4100
    },
    {
      "epoch": 0.5109903479600941,
      "grad_norm": 3.75,
      "learning_rate": 8.296629760311474e-05,
      "loss": 3.082,
      "step": 4200
    },
    {
      "epoch": 0.5231567848162868,
      "grad_norm": 3.515625,
      "learning_rate": 8.256073326033176e-05,
      "loss": 3.061,
      "step": 4300
    },
    {
      "epoch": 0.5353232216724795,
      "grad_norm": 1.4765625,
      "learning_rate": 8.215516891754877e-05,
      "loss": 2.561,
      "step": 4400
    },
    {
      "epoch": 0.5474896585286723,
      "grad_norm": 17.5,
      "learning_rate": 8.17496045747658e-05,
      "loss": 2.9673,
      "step": 4500
    },
    {
      "epoch": 0.5596560953848649,
      "grad_norm": 4.3125,
      "learning_rate": 8.134404023198281e-05,
      "loss": 2.47,
      "step": 4600
    },
    {
      "epoch": 0.5718225322410577,
      "grad_norm": 7.125,
      "learning_rate": 8.093847588919982e-05,
      "loss": 3.1729,
      "step": 4700
    },
    {
      "epoch": 0.5839889690972504,
      "grad_norm": 20.0,
      "learning_rate": 8.053291154641685e-05,
      "loss": 3.198,
      "step": 4800
    },
    {
      "epoch": 0.5961554059534431,
      "grad_norm": 2.765625,
      "learning_rate": 8.012734720363386e-05,
      "loss": 3.1715,
      "step": 4900
    },
    {
      "epoch": 0.6083218428096359,
      "grad_norm": 2.03125,
      "learning_rate": 7.972178286085088e-05,
      "loss": 2.7935,
      "step": 5000
    },
    {
      "epoch": 0.6204882796658285,
      "grad_norm": 4.625,
      "learning_rate": 7.93162185180679e-05,
      "loss": 3.2549,
      "step": 5100
    },
    {
      "epoch": 0.6326547165220212,
      "grad_norm": 9.0,
      "learning_rate": 7.891065417528492e-05,
      "loss": 2.7605,
      "step": 5200
    },
    {
      "epoch": 0.644821153378214,
      "grad_norm": 6.25,
      "learning_rate": 7.850508983250193e-05,
      "loss": 3.1544,
      "step": 5300
    },
    {
      "epoch": 0.6569875902344067,
      "grad_norm": 6.0625,
      "learning_rate": 7.809952548971894e-05,
      "loss": 2.7943,
      "step": 5400
    },
    {
      "epoch": 0.6691540270905993,
      "grad_norm": 14.3125,
      "learning_rate": 7.769396114693597e-05,
      "loss": 2.9873,
      "step": 5500
    },
    {
      "epoch": 0.6813204639467921,
      "grad_norm": 3.5,
      "learning_rate": 7.728839680415298e-05,
      "loss": 2.8458,
      "step": 5600
    },
    {
      "epoch": 0.6934869008029848,
      "grad_norm": 8.75,
      "learning_rate": 7.688283246137e-05,
      "loss": 2.865,
      "step": 5700
    },
    {
      "epoch": 0.7056533376591776,
      "grad_norm": 16.125,
      "learning_rate": 7.647726811858702e-05,
      "loss": 3.0264,
      "step": 5800
    },
    {
      "epoch": 0.7178197745153703,
      "grad_norm": 6.625,
      "learning_rate": 7.607170377580404e-05,
      "loss": 3.3423,
      "step": 5900
    },
    {
      "epoch": 0.7299862113715629,
      "grad_norm": 26.375,
      "learning_rate": 7.566613943302105e-05,
      "loss": 3.1351,
      "step": 6000
    },
    {
      "epoch": 0.7421526482277557,
      "grad_norm": 4.875,
      "learning_rate": 7.526057509023807e-05,
      "loss": 2.8082,
      "step": 6100
    },
    {
      "epoch": 0.7543190850839484,
      "grad_norm": 14.8125,
      "learning_rate": 7.485501074745509e-05,
      "loss": 2.6588,
      "step": 6200
    },
    {
      "epoch": 0.7664855219401411,
      "grad_norm": 6.65625,
      "learning_rate": 7.44494464046721e-05,
      "loss": 2.8739,
      "step": 6300
    },
    {
      "epoch": 0.7786519587963339,
      "grad_norm": 17.0,
      "learning_rate": 7.404388206188913e-05,
      "loss": 2.4005,
      "step": 6400
    },
    {
      "epoch": 0.7908183956525265,
      "grad_norm": 7.1875,
      "learning_rate": 7.363831771910614e-05,
      "loss": 2.7478,
      "step": 6500
    },
    {
      "epoch": 0.8029848325087193,
      "grad_norm": 16.25,
      "learning_rate": 7.323275337632316e-05,
      "loss": 2.5471,
      "step": 6600
    },
    {
      "epoch": 0.815151269364912,
      "grad_norm": 28.625,
      "learning_rate": 7.282718903354018e-05,
      "loss": 2.7594,
      "step": 6700
    },
    {
      "epoch": 0.8273177062211047,
      "grad_norm": 10.3125,
      "learning_rate": 7.242162469075719e-05,
      "loss": 3.0617,
      "step": 6800
    },
    {
      "epoch": 0.8394841430772975,
      "grad_norm": 5.5,
      "learning_rate": 7.201606034797421e-05,
      "loss": 3.311,
      "step": 6900
    },
    {
      "epoch": 0.8516505799334901,
      "grad_norm": 2.046875,
      "learning_rate": 7.161049600519122e-05,
      "loss": 3.0824,
      "step": 7000
    },
    {
      "epoch": 0.8638170167896828,
      "grad_norm": 3.65625,
      "learning_rate": 7.120493166240825e-05,
      "loss": 2.9601,
      "step": 7100
    },
    {
      "epoch": 0.8759834536458756,
      "grad_norm": 3.046875,
      "learning_rate": 7.079936731962526e-05,
      "loss": 2.6952,
      "step": 7200
    },
    {
      "epoch": 0.8881498905020683,
      "grad_norm": 21.375,
      "learning_rate": 7.039380297684229e-05,
      "loss": 2.5295,
      "step": 7300
    },
    {
      "epoch": 0.9003163273582611,
      "grad_norm": 5.125,
      "learning_rate": 6.99882386340593e-05,
      "loss": 3.0052,
      "step": 7400
    },
    {
      "epoch": 0.9124827642144537,
      "grad_norm": 23.625,
      "learning_rate": 6.958267429127632e-05,
      "loss": 3.3813,
      "step": 7500
    },
    {
      "epoch": 0.9246492010706464,
      "grad_norm": 5.8125,
      "learning_rate": 6.917710994849334e-05,
      "loss": 3.208,
      "step": 7600
    },
    {
      "epoch": 0.9368156379268392,
      "grad_norm": 10.5,
      "learning_rate": 6.877154560571035e-05,
      "loss": 3.5383,
      "step": 7700
    },
    {
      "epoch": 0.9489820747830319,
      "grad_norm": 3.46875,
      "learning_rate": 6.836598126292737e-05,
      "loss": 2.5402,
      "step": 7800
    },
    {
      "epoch": 0.9611485116392245,
      "grad_norm": 8.8125,
      "learning_rate": 6.796041692014438e-05,
      "loss": 2.715,
      "step": 7900
    },
    {
      "epoch": 0.9733149484954173,
      "grad_norm": 13.4375,
      "learning_rate": 6.755485257736141e-05,
      "loss": 3.0959,
      "step": 8000
    },
    {
      "epoch": 0.98548138535161,
      "grad_norm": 77.5,
      "learning_rate": 6.714928823457842e-05,
      "loss": 3.1556,
      "step": 8100
    },
    {
      "epoch": 0.9976478222078028,
      "grad_norm": 4.875,
      "learning_rate": 6.674372389179545e-05,
      "loss": 2.7987,
      "step": 8200
    },
    {
      "epoch": 1.0098142590639954,
      "grad_norm": 10.375,
      "learning_rate": 6.633815954901246e-05,
      "loss": 3.2188,
      "step": 8300
    },
    {
      "epoch": 1.0219806959201883,
      "grad_norm": 13.1875,
      "learning_rate": 6.593259520622947e-05,
      "loss": 2.955,
      "step": 8400
    },
    {
      "epoch": 1.034147132776381,
      "grad_norm": 8.625,
      "learning_rate": 6.55270308634465e-05,
      "loss": 2.3457,
      "step": 8500
    },
    {
      "epoch": 1.0463135696325736,
      "grad_norm": 5.65625,
      "learning_rate": 6.51214665206635e-05,
      "loss": 3.0899,
      "step": 8600
    },
    {
      "epoch": 1.0584800064887663,
      "grad_norm": 15.0625,
      "learning_rate": 6.471590217788053e-05,
      "loss": 2.7855,
      "step": 8700
    },
    {
      "epoch": 1.070646443344959,
      "grad_norm": 19.25,
      "learning_rate": 6.431033783509754e-05,
      "loss": 2.8976,
      "step": 8800
    },
    {
      "epoch": 1.0828128802011519,
      "grad_norm": 15.8125,
      "learning_rate": 6.390477349231457e-05,
      "loss": 2.4723,
      "step": 8900
    },
    {
      "epoch": 1.0949793170573445,
      "grad_norm": 4.125,
      "learning_rate": 6.349920914953158e-05,
      "loss": 2.9081,
      "step": 9000
    },
    {
      "epoch": 1.1071457539135372,
      "grad_norm": 4.09375,
      "learning_rate": 6.309364480674859e-05,
      "loss": 2.5813,
      "step": 9100
    },
    {
      "epoch": 1.1193121907697299,
      "grad_norm": 7.6875,
      "learning_rate": 6.268808046396562e-05,
      "loss": 2.7545,
      "step": 9200
    },
    {
      "epoch": 1.1314786276259226,
      "grad_norm": 2.265625,
      "learning_rate": 6.228251612118263e-05,
      "loss": 2.8011,
      "step": 9300
    },
    {
      "epoch": 1.1436450644821154,
      "grad_norm": 4.21875,
      "learning_rate": 6.187695177839965e-05,
      "loss": 2.8391,
      "step": 9400
    },
    {
      "epoch": 1.1558115013383081,
      "grad_norm": 2.8125,
      "learning_rate": 6.147138743561666e-05,
      "loss": 2.8281,
      "step": 9500
    },
    {
      "epoch": 1.1679779381945008,
      "grad_norm": 10.75,
      "learning_rate": 6.106582309283369e-05,
      "loss": 3.6089,
      "step": 9600
    },
    {
      "epoch": 1.1801443750506935,
      "grad_norm": 5.1875,
      "learning_rate": 6.06602587500507e-05,
      "loss": 2.7635,
      "step": 9700
    },
    {
      "epoch": 1.1923108119068861,
      "grad_norm": 8.125,
      "learning_rate": 6.025469440726772e-05,
      "loss": 2.5973,
      "step": 9800
    },
    {
      "epoch": 1.2044772487630788,
      "grad_norm": 4.125,
      "learning_rate": 5.984913006448474e-05,
      "loss": 2.729,
      "step": 9900
    },
    {
      "epoch": 1.2166436856192717,
      "grad_norm": 8.375,
      "learning_rate": 5.944356572170176e-05,
      "loss": 3.0779,
      "step": 10000
    },
    {
      "epoch": 1.2288101224754644,
      "grad_norm": 6.28125,
      "learning_rate": 5.9038001378918775e-05,
      "loss": 2.5092,
      "step": 10100
    },
    {
      "epoch": 1.240976559331657,
      "grad_norm": 13.5,
      "learning_rate": 5.863243703613579e-05,
      "loss": 3.3426,
      "step": 10200
    },
    {
      "epoch": 1.2531429961878497,
      "grad_norm": 2.671875,
      "learning_rate": 5.8226872693352805e-05,
      "loss": 3.0797,
      "step": 10300
    },
    {
      "epoch": 1.2653094330440424,
      "grad_norm": 2.640625,
      "learning_rate": 5.7821308350569823e-05,
      "loss": 3.3526,
      "step": 10400
    },
    {
      "epoch": 1.2774758699002353,
      "grad_norm": 17.625,
      "learning_rate": 5.741574400778684e-05,
      "loss": 3.6027,
      "step": 10500
    },
    {
      "epoch": 1.289642306756428,
      "grad_norm": 11.1875,
      "learning_rate": 5.701017966500386e-05,
      "loss": 3.376,
      "step": 10600
    },
    {
      "epoch": 1.3018087436126207,
      "grad_norm": 7.03125,
      "learning_rate": 5.660461532222088e-05,
      "loss": 2.9633,
      "step": 10700
    },
    {
      "epoch": 1.3139751804688133,
      "grad_norm": 4.09375,
      "learning_rate": 5.61990509794379e-05,
      "loss": 2.7086,
      "step": 10800
    },
    {
      "epoch": 1.326141617325006,
      "grad_norm": 3.78125,
      "learning_rate": 5.5793486636654915e-05,
      "loss": 2.7681,
      "step": 10900
    },
    {
      "epoch": 1.3383080541811987,
      "grad_norm": 16.625,
      "learning_rate": 5.538792229387193e-05,
      "loss": 2.7047,
      "step": 11000
    },
    {
      "epoch": 1.3504744910373916,
      "grad_norm": 3.1875,
      "learning_rate": 5.4982357951088945e-05,
      "loss": 2.9748,
      "step": 11100
    },
    {
      "epoch": 1.3626409278935843,
      "grad_norm": 17.125,
      "learning_rate": 5.4576793608305964e-05,
      "loss": 2.883,
      "step": 11200
    },
    {
      "epoch": 1.374807364749777,
      "grad_norm": 2.140625,
      "learning_rate": 5.417122926552298e-05,
      "loss": 3.4959,
      "step": 11300
    },
    {
      "epoch": 1.3869738016059696,
      "grad_norm": 7.6875,
      "learning_rate": 5.376566492274e-05,
      "loss": 2.2988,
      "step": 11400
    },
    {
      "epoch": 1.3991402384621625,
      "grad_norm": 1.8984375,
      "learning_rate": 5.336010057995702e-05,
      "loss": 3.1288,
      "step": 11500
    },
    {
      "epoch": 1.4113066753183552,
      "grad_norm": 6.625,
      "learning_rate": 5.295453623717404e-05,
      "loss": 3.245,
      "step": 11600
    },
    {
      "epoch": 1.4234731121745479,
      "grad_norm": 6.96875,
      "learning_rate": 5.2548971894391056e-05,
      "loss": 2.7842,
      "step": 11700
    },
    {
      "epoch": 1.4356395490307405,
      "grad_norm": 3.125,
      "learning_rate": 5.214340755160807e-05,
      "loss": 3.3412,
      "step": 11800
    },
    {
      "epoch": 1.4478059858869332,
      "grad_norm": 3.6875,
      "learning_rate": 5.1737843208825086e-05,
      "loss": 2.9118,
      "step": 11900
    },
    {
      "epoch": 1.4599724227431259,
      "grad_norm": 20.375,
      "learning_rate": 5.1332278866042104e-05,
      "loss": 2.7341,
      "step": 12000
    },
    {
      "epoch": 1.4721388595993186,
      "grad_norm": 4.25,
      "learning_rate": 5.092671452325912e-05,
      "loss": 3.5711,
      "step": 12100
    },
    {
      "epoch": 1.4843052964555115,
      "grad_norm": 6.6875,
      "learning_rate": 5.052115018047614e-05,
      "loss": 2.5149,
      "step": 12200
    },
    {
      "epoch": 1.4964717333117041,
      "grad_norm": 7.5,
      "learning_rate": 5.011558583769316e-05,
      "loss": 2.8146,
      "step": 12300
    },
    {
      "epoch": 1.5086381701678968,
      "grad_norm": 3.53125,
      "learning_rate": 4.971002149491017e-05,
      "loss": 2.2924,
      "step": 12400
    },
    {
      "epoch": 1.5208046070240897,
      "grad_norm": 24.75,
      "learning_rate": 4.930445715212719e-05,
      "loss": 2.9701,
      "step": 12500
    },
    {
      "epoch": 1.5329710438802824,
      "grad_norm": 1.4765625,
      "learning_rate": 4.88988928093442e-05,
      "loss": 2.3843,
      "step": 12600
    },
    {
      "epoch": 1.545137480736475,
      "grad_norm": 5.5625,
      "learning_rate": 4.849332846656122e-05,
      "loss": 3.2473,
      "step": 12700
    },
    {
      "epoch": 1.5573039175926677,
      "grad_norm": 5.5625,
      "learning_rate": 4.808776412377824e-05,
      "loss": 2.8256,
      "step": 12800
    },
    {
      "epoch": 1.5694703544488604,
      "grad_norm": 45.5,
      "learning_rate": 4.7682199780995256e-05,
      "loss": 2.939,
      "step": 12900
    },
    {
      "epoch": 1.581636791305053,
      "grad_norm": 1.921875,
      "learning_rate": 4.7276635438212275e-05,
      "loss": 2.9016,
      "step": 13000
    },
    {
      "epoch": 1.5938032281612458,
      "grad_norm": 7.84375,
      "learning_rate": 4.687107109542929e-05,
      "loss": 2.6744,
      "step": 13100
    },
    {
      "epoch": 1.6059696650174384,
      "grad_norm": 23.5,
      "learning_rate": 4.646550675264631e-05,
      "loss": 2.2776,
      "step": 13200
    },
    {
      "epoch": 1.6181361018736313,
      "grad_norm": 6.40625,
      "learning_rate": 4.605994240986333e-05,
      "loss": 2.7835,
      "step": 13300
    },
    {
      "epoch": 1.630302538729824,
      "grad_norm": 8.125,
      "learning_rate": 4.565437806708034e-05,
      "loss": 2.6958,
      "step": 13400
    },
    {
      "epoch": 1.6424689755860167,
      "grad_norm": 17.625,
      "learning_rate": 4.524881372429736e-05,
      "loss": 2.856,
      "step": 13500
    },
    {
      "epoch": 1.6546354124422096,
      "grad_norm": 24.625,
      "learning_rate": 4.484324938151438e-05,
      "loss": 2.9351,
      "step": 13600
    },
    {
      "epoch": 1.6668018492984022,
      "grad_norm": 7.09375,
      "learning_rate": 4.44376850387314e-05,
      "loss": 2.8964,
      "step": 13700
    },
    {
      "epoch": 1.678968286154595,
      "grad_norm": 55.25,
      "learning_rate": 4.4032120695948415e-05,
      "loss": 2.7884,
      "step": 13800
    },
    {
      "epoch": 1.6911347230107876,
      "grad_norm": 8.0625,
      "learning_rate": 4.3626556353165434e-05,
      "loss": 2.8637,
      "step": 13900
    },
    {
      "epoch": 1.7033011598669803,
      "grad_norm": 7.0625,
      "learning_rate": 4.322099201038245e-05,
      "loss": 2.6834,
      "step": 14000
    },
    {
      "epoch": 1.715467596723173,
      "grad_norm": 3.734375,
      "learning_rate": 4.281542766759947e-05,
      "loss": 3.2618,
      "step": 14100
    },
    {
      "epoch": 1.7276340335793656,
      "grad_norm": 1.3046875,
      "learning_rate": 4.240986332481648e-05,
      "loss": 3.196,
      "step": 14200
    },
    {
      "epoch": 1.7398004704355583,
      "grad_norm": 2.453125,
      "learning_rate": 4.20042989820335e-05,
      "loss": 3.5375,
      "step": 14300
    },
    {
      "epoch": 1.7519669072917512,
      "grad_norm": 3.90625,
      "learning_rate": 4.159873463925052e-05,
      "loss": 2.2288,
      "step": 14400
    },
    {
      "epoch": 1.7641333441479439,
      "grad_norm": 18.5,
      "learning_rate": 4.119317029646754e-05,
      "loss": 2.5836,
      "step": 14500
    },
    {
      "epoch": 1.7762997810041365,
      "grad_norm": 6.0,
      "learning_rate": 4.0787605953684556e-05,
      "loss": 3.1246,
      "step": 14600
    },
    {
      "epoch": 1.7884662178603294,
      "grad_norm": 4.78125,
      "learning_rate": 4.0382041610901574e-05,
      "loss": 2.5261,
      "step": 14700
    },
    {
      "epoch": 1.8006326547165221,
      "grad_norm": 20.875,
      "learning_rate": 3.997647726811859e-05,
      "loss": 2.5578,
      "step": 14800
    },
    {
      "epoch": 1.8127990915727148,
      "grad_norm": 4.15625,
      "learning_rate": 3.9570912925335604e-05,
      "loss": 3.1478,
      "step": 14900
    },
    {
      "epoch": 1.8249655284289075,
      "grad_norm": 4.78125,
      "learning_rate": 3.916534858255262e-05,
      "loss": 3.0886,
      "step": 15000
    },
    {
      "epoch": 1.8371319652851001,
      "grad_norm": 21.875,
      "learning_rate": 3.875978423976964e-05,
      "loss": 2.5529,
      "step": 15100
    },
    {
      "epoch": 1.8492984021412928,
      "grad_norm": 5.3125,
      "learning_rate": 3.835421989698666e-05,
      "loss": 2.5268,
      "step": 15200
    },
    {
      "epoch": 1.8614648389974855,
      "grad_norm": 6.96875,
      "learning_rate": 3.794865555420368e-05,
      "loss": 2.4507,
      "step": 15300
    },
    {
      "epoch": 1.8736312758536782,
      "grad_norm": 2.484375,
      "learning_rate": 3.7543091211420696e-05,
      "loss": 2.9537,
      "step": 15400
    },
    {
      "epoch": 1.885797712709871,
      "grad_norm": 4.34375,
      "learning_rate": 3.7137526868637714e-05,
      "loss": 2.6194,
      "step": 15500
    },
    {
      "epoch": 1.8979641495660637,
      "grad_norm": 8.375,
      "learning_rate": 3.673196252585473e-05,
      "loss": 3.0051,
      "step": 15600
    },
    {
      "epoch": 1.9101305864222564,
      "grad_norm": 16.625,
      "learning_rate": 3.6326398183071744e-05,
      "loss": 2.7309,
      "step": 15700
    },
    {
      "epoch": 1.9222970232784493,
      "grad_norm": 3.6875,
      "learning_rate": 3.592083384028876e-05,
      "loss": 2.5734,
      "step": 15800
    },
    {
      "epoch": 1.934463460134642,
      "grad_norm": 7.25,
      "learning_rate": 3.551526949750578e-05,
      "loss": 3.0383,
      "step": 15900
    },
    {
      "epoch": 1.9466298969908347,
      "grad_norm": 5.9375,
      "learning_rate": 3.51097051547228e-05,
      "loss": 3.1128,
      "step": 16000
    },
    {
      "epoch": 1.9587963338470273,
      "grad_norm": 4.46875,
      "learning_rate": 3.470414081193982e-05,
      "loss": 3.1938,
      "step": 16100
    },
    {
      "epoch": 1.97096277070322,
      "grad_norm": 7.625,
      "learning_rate": 3.4298576469156836e-05,
      "loss": 3.1549,
      "step": 16200
    },
    {
      "epoch": 1.9831292075594127,
      "grad_norm": 8.8125,
      "learning_rate": 3.3893012126373855e-05,
      "loss": 3.0079,
      "step": 16300
    },
    {
      "epoch": 1.9952956444156054,
      "grad_norm": 16.875,
      "learning_rate": 3.3487447783590866e-05,
      "loss": 3.5201,
      "step": 16400
    },
    {
      "epoch": 2.007462081271798,
      "grad_norm": 2.96875,
      "learning_rate": 3.3081883440807885e-05,
      "loss": 2.5072,
      "step": 16500
    },
    {
      "epoch": 2.0196285181279907,
      "grad_norm": 20.125,
      "learning_rate": 3.26763190980249e-05,
      "loss": 3.4103,
      "step": 16600
    },
    {
      "epoch": 2.031794954984184,
      "grad_norm": 12.5,
      "learning_rate": 3.227075475524192e-05,
      "loss": 3.1185,
      "step": 16700
    },
    {
      "epoch": 2.0439613918403765,
      "grad_norm": 3.6875,
      "learning_rate": 3.186519041245894e-05,
      "loss": 2.6652,
      "step": 16800
    },
    {
      "epoch": 2.056127828696569,
      "grad_norm": 3.53125,
      "learning_rate": 3.145962606967596e-05,
      "loss": 2.394,
      "step": 16900
    },
    {
      "epoch": 2.068294265552762,
      "grad_norm": 8.75,
      "learning_rate": 3.105406172689298e-05,
      "loss": 3.0586,
      "step": 17000
    },
    {
      "epoch": 2.0804607024089545,
      "grad_norm": 4.25,
      "learning_rate": 3.0648497384109995e-05,
      "loss": 3.1468,
      "step": 17100
    },
    {
      "epoch": 2.092627139265147,
      "grad_norm": 6.4375,
      "learning_rate": 3.024293304132701e-05,
      "loss": 2.7969,
      "step": 17200
    },
    {
      "epoch": 2.10479357612134,
      "grad_norm": 2.703125,
      "learning_rate": 2.983736869854403e-05,
      "loss": 3.0453,
      "step": 17300
    },
    {
      "epoch": 2.1169600129775326,
      "grad_norm": 5.84375,
      "learning_rate": 2.9431804355761044e-05,
      "loss": 2.9918,
      "step": 17400
    },
    {
      "epoch": 2.1291264498337252,
      "grad_norm": 9.0,
      "learning_rate": 2.9026240012978062e-05,
      "loss": 2.4491,
      "step": 17500
    },
    {
      "epoch": 2.141292886689918,
      "grad_norm": 3.859375,
      "learning_rate": 2.862067567019508e-05,
      "loss": 3.0178,
      "step": 17600
    },
    {
      "epoch": 2.1534593235461106,
      "grad_norm": 18.25,
      "learning_rate": 2.8215111327412095e-05,
      "loss": 2.5986,
      "step": 17700
    },
    {
      "epoch": 2.1656257604023037,
      "grad_norm": 9.125,
      "learning_rate": 2.7809546984629114e-05,
      "loss": 2.4869,
      "step": 17800
    },
    {
      "epoch": 2.1777921972584964,
      "grad_norm": 10.75,
      "learning_rate": 2.7403982641846132e-05,
      "loss": 2.9795,
      "step": 17900
    },
    {
      "epoch": 2.189958634114689,
      "grad_norm": 2.296875,
      "learning_rate": 2.699841829906315e-05,
      "loss": 2.9604,
      "step": 18000
    },
    {
      "epoch": 2.2021250709708817,
      "grad_norm": 6.46875,
      "learning_rate": 2.6592853956280166e-05,
      "loss": 2.8446,
      "step": 18100
    },
    {
      "epoch": 2.2142915078270744,
      "grad_norm": 16.625,
      "learning_rate": 2.6187289613497184e-05,
      "loss": 2.6576,
      "step": 18200
    },
    {
      "epoch": 2.226457944683267,
      "grad_norm": 12.375,
      "learning_rate": 2.5781725270714202e-05,
      "loss": 3.3504,
      "step": 18300
    },
    {
      "epoch": 2.2386243815394598,
      "grad_norm": 6.59375,
      "learning_rate": 2.537616092793122e-05,
      "loss": 2.7719,
      "step": 18400
    },
    {
      "epoch": 2.2507908183956524,
      "grad_norm": 5.625,
      "learning_rate": 2.4970596585148236e-05,
      "loss": 2.8085,
      "step": 18500
    },
    {
      "epoch": 2.262957255251845,
      "grad_norm": 5.46875,
      "learning_rate": 2.456503224236525e-05,
      "loss": 2.8291,
      "step": 18600
    },
    {
      "epoch": 2.2751236921080378,
      "grad_norm": 9.75,
      "learning_rate": 2.415946789958227e-05,
      "loss": 2.6249,
      "step": 18700
    },
    {
      "epoch": 2.287290128964231,
      "grad_norm": 1.5078125,
      "learning_rate": 2.3753903556799288e-05,
      "loss": 3.2995,
      "step": 18800
    },
    {
      "epoch": 2.2994565658204236,
      "grad_norm": 5.3125,
      "learning_rate": 2.3348339214016303e-05,
      "loss": 2.8904,
      "step": 18900
    },
    {
      "epoch": 2.3116230026766162,
      "grad_norm": 13.125,
      "learning_rate": 2.294277487123332e-05,
      "loss": 2.7366,
      "step": 19000
    },
    {
      "epoch": 2.323789439532809,
      "grad_norm": 8.875,
      "learning_rate": 2.253721052845034e-05,
      "loss": 2.4071,
      "step": 19100
    },
    {
      "epoch": 2.3359558763890016,
      "grad_norm": 9.5625,
      "learning_rate": 2.2131646185667358e-05,
      "loss": 2.8738,
      "step": 19200
    },
    {
      "epoch": 2.3481223132451943,
      "grad_norm": 7.25,
      "learning_rate": 2.1726081842884373e-05,
      "loss": 2.96,
      "step": 19300
    },
    {
      "epoch": 2.360288750101387,
      "grad_norm": 11.875,
      "learning_rate": 2.132051750010139e-05,
      "loss": 3.4931,
      "step": 19400
    },
    {
      "epoch": 2.3724551869575796,
      "grad_norm": 3.671875,
      "learning_rate": 2.091495315731841e-05,
      "loss": 2.6228,
      "step": 19500
    },
    {
      "epoch": 2.3846216238137723,
      "grad_norm": 12.6875,
      "learning_rate": 2.0509388814535428e-05,
      "loss": 3.1877,
      "step": 19600
    },
    {
      "epoch": 2.396788060669965,
      "grad_norm": 16.125,
      "learning_rate": 2.0103824471752443e-05,
      "loss": 3.0064,
      "step": 19700
    },
    {
      "epoch": 2.4089544975261576,
      "grad_norm": 12.0625,
      "learning_rate": 1.969826012896946e-05,
      "loss": 2.8484,
      "step": 19800
    },
    {
      "epoch": 2.4211209343823503,
      "grad_norm": 34.25,
      "learning_rate": 1.929269578618648e-05,
      "loss": 3.1237,
      "step": 19900
    },
    {
      "epoch": 2.4332873712385434,
      "grad_norm": 7.4375,
      "learning_rate": 1.88871314434035e-05,
      "loss": 2.7176,
      "step": 20000
    },
    {
      "epoch": 2.445453808094736,
      "grad_norm": 2.078125,
      "learning_rate": 1.8481567100620513e-05,
      "loss": 2.9222,
      "step": 20100
    },
    {
      "epoch": 2.457620244950929,
      "grad_norm": 2.890625,
      "learning_rate": 1.8076002757837532e-05,
      "loss": 3.0467,
      "step": 20200
    },
    {
      "epoch": 2.4697866818071215,
      "grad_norm": 47.75,
      "learning_rate": 1.767043841505455e-05,
      "loss": 2.7999,
      "step": 20300
    },
    {
      "epoch": 2.481953118663314,
      "grad_norm": 13.375,
      "learning_rate": 1.7264874072271565e-05,
      "loss": 2.9223,
      "step": 20400
    },
    {
      "epoch": 2.494119555519507,
      "grad_norm": 3.890625,
      "learning_rate": 1.6859309729488584e-05,
      "loss": 2.6916,
      "step": 20500
    },
    {
      "epoch": 2.5062859923756995,
      "grad_norm": 11.875,
      "learning_rate": 1.6453745386705602e-05,
      "loss": 2.8146,
      "step": 20600
    },
    {
      "epoch": 2.518452429231892,
      "grad_norm": 4.375,
      "learning_rate": 1.604818104392262e-05,
      "loss": 2.9916,
      "step": 20700
    },
    {
      "epoch": 2.530618866088085,
      "grad_norm": 5.8125,
      "learning_rate": 1.5642616701139635e-05,
      "loss": 2.6809,
      "step": 20800
    },
    {
      "epoch": 2.542785302944278,
      "grad_norm": 22.625,
      "learning_rate": 1.5237052358356654e-05,
      "loss": 2.9737,
      "step": 20900
    },
    {
      "epoch": 2.5549517398004706,
      "grad_norm": 5.96875,
      "learning_rate": 1.4831488015573672e-05,
      "loss": 2.5364,
      "step": 21000
    },
    {
      "epoch": 2.5671181766566633,
      "grad_norm": 4.625,
      "learning_rate": 1.4425923672790689e-05,
      "loss": 3.0414,
      "step": 21100
    },
    {
      "epoch": 2.579284613512856,
      "grad_norm": 8.8125,
      "learning_rate": 1.4020359330007707e-05,
      "loss": 3.9354,
      "step": 21200
    },
    {
      "epoch": 2.5914510503690487,
      "grad_norm": 6.0,
      "learning_rate": 1.3614794987224724e-05,
      "loss": 3.2283,
      "step": 21300
    },
    {
      "epoch": 2.6036174872252413,
      "grad_norm": 4.25,
      "learning_rate": 1.3209230644441742e-05,
      "loss": 2.9067,
      "step": 21400
    },
    {
      "epoch": 2.615783924081434,
      "grad_norm": 1.640625,
      "learning_rate": 1.2803666301658759e-05,
      "loss": 2.7439,
      "step": 21500
    },
    {
      "epoch": 2.6279503609376267,
      "grad_norm": 3.71875,
      "learning_rate": 1.2398101958875777e-05,
      "loss": 2.7552,
      "step": 21600
    },
    {
      "epoch": 2.6401167977938194,
      "grad_norm": 4.15625,
      "learning_rate": 1.1992537616092794e-05,
      "loss": 2.6046,
      "step": 21700
    },
    {
      "epoch": 2.652283234650012,
      "grad_norm": 12.1875,
      "learning_rate": 1.1586973273309811e-05,
      "loss": 2.7335,
      "step": 21800
    },
    {
      "epoch": 2.6644496715062047,
      "grad_norm": 14.5625,
      "learning_rate": 1.1181408930526828e-05,
      "loss": 2.8552,
      "step": 21900
    },
    {
      "epoch": 2.6766161083623974,
      "grad_norm": 1.78125,
      "learning_rate": 1.0775844587743846e-05,
      "loss": 2.2888,
      "step": 22000
    },
    {
      "epoch": 2.68878254521859,
      "grad_norm": 3.03125,
      "learning_rate": 1.0370280244960863e-05,
      "loss": 3.0155,
      "step": 22100
    },
    {
      "epoch": 2.700948982074783,
      "grad_norm": 9.5625,
      "learning_rate": 9.964715902177881e-06,
      "loss": 2.4827,
      "step": 22200
    },
    {
      "epoch": 2.713115418930976,
      "grad_norm": 2.203125,
      "learning_rate": 9.559151559394898e-06,
      "loss": 3.1638,
      "step": 22300
    },
    {
      "epoch": 2.7252818557871685,
      "grad_norm": 17.125,
      "learning_rate": 9.153587216611916e-06,
      "loss": 3.3031,
      "step": 22400
    },
    {
      "epoch": 2.737448292643361,
      "grad_norm": 4.21875,
      "learning_rate": 8.748022873828933e-06,
      "loss": 2.9541,
      "step": 22500
    },
    {
      "epoch": 2.749614729499554,
      "grad_norm": 4.21875,
      "learning_rate": 8.342458531045951e-06,
      "loss": 3.5606,
      "step": 22600
    },
    {
      "epoch": 2.7617811663557466,
      "grad_norm": 6.375,
      "learning_rate": 7.936894188262968e-06,
      "loss": 2.7048,
      "step": 22700
    },
    {
      "epoch": 2.7739476032119392,
      "grad_norm": 3.984375,
      "learning_rate": 7.5313298454799856e-06,
      "loss": 2.564,
      "step": 22800
    },
    {
      "epoch": 2.786114040068132,
      "grad_norm": 18.375,
      "learning_rate": 7.125765502697003e-06,
      "loss": 3.23,
      "step": 22900
    },
    {
      "epoch": 2.798280476924325,
      "grad_norm": 2.171875,
      "learning_rate": 6.720201159914021e-06,
      "loss": 2.7413,
      "step": 23000
    },
    {
      "epoch": 2.8104469137805177,
      "grad_norm": 16.25,
      "learning_rate": 6.314636817131038e-06,
      "loss": 2.3675,
      "step": 23100
    },
    {
      "epoch": 2.8226133506367104,
      "grad_norm": 21.125,
      "learning_rate": 5.909072474348056e-06,
      "loss": 2.4917,
      "step": 23200
    },
    {
      "epoch": 2.834779787492903,
      "grad_norm": 21.5,
      "learning_rate": 5.503508131565073e-06,
      "loss": 2.6393,
      "step": 23300
    },
    {
      "epoch": 2.8469462243490957,
      "grad_norm": 7.875,
      "learning_rate": 5.097943788782091e-06,
      "loss": 2.8167,
      "step": 23400
    },
    {
      "epoch": 2.8591126612052884,
      "grad_norm": 4.25,
      "learning_rate": 4.692379445999108e-06,
      "loss": 2.7447,
      "step": 23500
    },
    {
      "epoch": 2.871279098061481,
      "grad_norm": 4.46875,
      "learning_rate": 4.286815103216125e-06,
      "loss": 2.7046,
      "step": 23600
    },
    {
      "epoch": 2.8834455349176737,
      "grad_norm": 16.75,
      "learning_rate": 3.881250760433143e-06,
      "loss": 2.5903,
      "step": 23700
    },
    {
      "epoch": 2.8956119717738664,
      "grad_norm": 2.609375,
      "learning_rate": 3.4756864176501607e-06,
      "loss": 2.7831,
      "step": 23800
    },
    {
      "epoch": 2.907778408630059,
      "grad_norm": 4.96875,
      "learning_rate": 3.070122074867178e-06,
      "loss": 2.6615,
      "step": 23900
    },
    {
      "epoch": 2.9199448454862518,
      "grad_norm": 9.875,
      "learning_rate": 2.6645577320841953e-06,
      "loss": 2.6395,
      "step": 24000
    },
    {
      "epoch": 2.9321112823424444,
      "grad_norm": 16.375,
      "learning_rate": 2.2589933893012125e-06,
      "loss": 2.6895,
      "step": 24100
    },
    {
      "epoch": 2.944277719198637,
      "grad_norm": 6.78125,
      "learning_rate": 1.8534290465182302e-06,
      "loss": 2.8721,
      "step": 24200
    },
    {
      "epoch": 2.9564441560548302,
      "grad_norm": 5.78125,
      "learning_rate": 1.4478647037352476e-06,
      "loss": 2.9376,
      "step": 24300
    },
    {
      "epoch": 2.968610592911023,
      "grad_norm": 3.734375,
      "learning_rate": 1.0423003609522651e-06,
      "loss": 2.8548,
      "step": 24400
    },
    {
      "epoch": 2.9807770297672156,
      "grad_norm": 10.8125,
      "learning_rate": 6.367360181692826e-07,
      "loss": 2.8298,
      "step": 24500
    },
    {
      "epoch": 2.9929434666234083,
      "grad_norm": 4.5625,
      "learning_rate": 2.3117167538630006e-07,
      "loss": 2.7129,
      "step": 24600
    },
    {
      "epoch": 2.999878335631438,
      "step": 24657,
      "total_flos": 6.279482773640053e+18,
      "train_loss": 2.965402161837659,
      "train_runtime": 38353.7689,
      "train_samples_per_second": 15.43,
      "train_steps_per_second": 0.643
    }
  ],
  "logging_steps": 100,
  "max_steps": 24657,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.279482773640053e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
